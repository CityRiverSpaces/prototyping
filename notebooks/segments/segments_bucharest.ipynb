{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import momepy\n",
    "import numpy as np\n",
    "import osmnx\n",
    "import pandas as pd\n",
    "import sklearn.cluster\n",
    "import shapely.ops\n",
    "\n",
    "from pandas import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corridor Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = \"Bucharest\"\n",
    "river_name = \"Dâmbovița\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = geopandas.read_file(f\"../data/generated/street_network_edges_{city_name}.gpkg\")\n",
    "nodes = geopandas.read_file(f\"../data/generated/street_network_nodes_{city_name}.gpkg\")\n",
    "waterway = geopandas.read_file(f\"../data/generated/waterway_{river_name}.gpkg\")\n",
    "corridor = geopandas.read_file(f\"../data/generated/corridor_{river_name}.gpkg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning with OSMnx\n",
    "\n",
    "Ultimately not superior to what can be done with sfnetworks. Also, does not seem to work smoothly everywhere. Skipping it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes['x'] = nodes.geometry.x\n",
    "nodes['y'] = nodes.geometry.y\n",
    "nodes = nodes.rename_axis('osmid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges['key'] = 0\n",
    "edges['osmid'] = edges.index\n",
    "edges = edges.rename({'from': 'u', 'to': 'v'}, axis='columns')\n",
    "edges = edges.set_index(['u', 'v', 'key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = osmnx.graph_from_gdfs(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fails, who knows why\n",
    "# g_consolidated = osmnx.consolidate_intersections(g, rebuild_graph=True, tolerance=15, dead_ends=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducing example notebook seems to work.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 37.858495, -122.267468\n",
    "G = osmnx.graph_from_point(point, network_type=\"drive\", dist=500)\n",
    "G_proj = osmnx.project_graph(G)\n",
    "n, e = osmnx.graph_to_gdfs(G_proj)\n",
    "r = osmnx.graph_from_gdfs(n, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = osmnx.consolidate_intersections(r, rebuild_graph=True, tolerance=20, dead_ends=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in range(len(continuity.stroke_gdf())) if i not in continuity.stroke_attribute().unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strokes.reset_index().explore(column=\"stroke_group\", cmap=\"prism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert highway level to category - it makes it easier to merge attributes for the strokes\n",
    "cat = CategoricalDtype(categories=['motorway', 'primary', 'secondary', 'tertiary'], ordered=True)\n",
    "edges[\"highway\"] = edges[\"highway\"].astype(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make continuity analysis using COINS\n",
    "continuity = momepy.COINS(edges)\n",
    "# strokes = continuity.stroke_gdf()  # this somehow differ from what we get from the procedure below ...\n",
    "edges[\"stroke_group\"] = continuity.stroke_attribute()\n",
    "strokes = edges.dissolve(by=\"stroke_group\", aggfunc=\"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting strokes up to primary, and comparing it with the original level attributes\n",
    "m = corridor.explore()\n",
    "m = edges[edges[\"highway\"] == \"secondary\"].reset_index().explore(m=m, color=\"black\")\n",
    "m = edges[edges[\"highway\"] <= \"primary\"].reset_index().explore(m=m, color=\"red\")\n",
    "m = strokes[strokes[\"highway\"] <= \"primary\"].reset_index().explore(m=m, color=\"green\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the corridor into blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_edges(edges, geometry, max_level=\"primary\"):\n",
    "    \"\"\"\n",
    "    Select edges that intersect the corridor, up to a\n",
    "    specified level for 'highway'\n",
    "    \"\"\"\n",
    "    filtered = edges[edges[\"highway\"] <= max_level]\n",
    "    return filtered[filtered.intersects(geometry)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blocks(edges: geopandas.GeoSeries, corridor: shapely.Polygon):\n",
    "    \"\"\"\n",
    "    Clip `corridor_geom` into blocks using LineStrings\n",
    "    from `edge_geoms` (both as geopandas.GeoSeries)\n",
    "    \"\"\"\n",
    "    lines = edges.to_list()\n",
    "    lines.append(corridor.boundary)\n",
    "    lines_merged = shapely.ops.linemerge(lines)\n",
    "    border_lines = shapely.ops.unary_union(lines_merged)\n",
    "    decomposition = shapely.ops.polygonize(border_lines)\n",
    "\n",
    "    # decomposition can extend beyond the corridor - clip it now\n",
    "    decomposition_gdf = geopandas.GeoSeries(decomposition, crs=edges.crs)\n",
    "    blocks = decomposition_gdf.clip(corridor)\n",
    "    return blocks[blocks.type == \"Polygon\"]  # drop elements at the edges (LineStrings and Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the strokes to break corridor into blocks\n",
    "corridor_geom = corridor.iloc[0].geometry\n",
    "strokes_intersecting = filter_edges(strokes, corridor_geom)\n",
    "blocks_strokes = get_blocks(\n",
    "    strokes_intersecting.explode().geometry, # split multilinestrings\n",
    "    corridor_geom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_strokes.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the original network to break corridor into blocks\n",
    "edges_intersecting = filter_edges(edges, corridor_geom)\n",
    "blocks_edges = get_blocks(\n",
    "    edges_intersecting.explode().geometry, # split multilinestrings\n",
    "    corridor_geom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_edges.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the midpoints of the river segments\n",
    "\n",
    "These are expected to represent the \"centroids\" of the segments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the river geometry and the street network of interest\n",
    "waterway_geom = waterway.iloc[0].geometry\n",
    "streets = edges[edges['highway'] <= \"primary\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the crossings as intersections between river and  the street network\n",
    "geoms = streets.intersection(waterway_geom)\n",
    "crossings = geoms[~geoms.geometry.is_empty]  # this should now be \"point\" geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the crossings in clusters and dissolve the grouped points into centroids\n",
    "xy = np.column_stack([crossings.x, crossings.y])\n",
    "dbscan = sklearn.cluster.DBSCAN(eps=100, min_samples=1)\n",
    "dbscan.fit(xy)\n",
    "crossings_clustered = crossings.to_frame(\"geometry\")\n",
    "crossings_clustered['cluster'] = dbscan.labels_\n",
    "crossings_dissolved = crossings_clustered.dissolve(by=\"cluster\").centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find distances of (clustered) crossings along the waterway and sort them\n",
    "dists = shapely.line_locate_point(waterway_geom, crossings_dissolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify midpoints between (clustered) crossings: these distances are used to find the centroids of the segments!\n",
    "dist_endpoints = [0., *sorted(dists), waterway_geom.length]\n",
    "dist_centroids = list(map(\n",
    "    lambda x: sum(x)/len(x),\n",
    "    zip(dist_endpoints[1:], dist_endpoints[:-1])\n",
    "))\n",
    "centroids = waterway_geom.interpolate(dist_centroids)\n",
    "centroids = geopandas.GeoDataFrame(geometry=centroids, crs=waterway.crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the blocks into the river segments\n",
    "\n",
    "### 1. Using the blocks from the strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt 1.1: merging the blocks that are closest to the centroids of the segments\n",
    "blocks_grouped = blocks_strokes.to_frame(\"geometry\").sjoin_nearest(centroids)\n",
    "segments = blocks_grouped.dissolve(by=\"index_right\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.explore(column=\"index_right\", categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt 1.2: merging the blocks whose centroids are closest to centroids of the segments\n",
    "blocks_grouped = blocks_strokes.to_frame('block')\n",
    "blocks_grouped['centroid'] = blocks_grouped.centroid\n",
    "blocks_grouped = blocks_grouped \\\n",
    "    .set_geometry('centroid') \\\n",
    "    .sjoin_nearest(centroids) \\\n",
    "    .set_geometry('block')\n",
    "segments = blocks_grouped.dissolve(by=\"index_right\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.explore(column=\"index_right\", categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using the blocks from the original network edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt 2.1: merging the blocks that are closest to the centroids of the segments\n",
    "blocks_grouped = blocks_edges.to_frame(\"geometry\").sjoin_nearest(centroids)\n",
    "segments = blocks_grouped.dissolve(by=\"index_right\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.explore(column=\"index_right\", categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt 2.2: merging the blocks whose centroids are closest to centroids of the segments\n",
    "blocks_grouped = blocks_edges.to_frame('block')\n",
    "blocks_grouped['centroid'] = blocks_grouped.centroid\n",
    "blocks_grouped = blocks_grouped \\\n",
    "    .set_geometry('centroid') \\\n",
    "    .sjoin_nearest(centroids) \\\n",
    "    .set_geometry('block')\n",
    "segments = blocks_grouped.dissolve(by=\"index_right\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.explore(column=\"index_right\", categorical=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
