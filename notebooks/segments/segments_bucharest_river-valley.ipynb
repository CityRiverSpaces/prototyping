{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import geopandas as gpd\n",
    "import momepy\n",
    "import momepy.coins\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.cluster\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it is the latest momepy\n",
    "momepy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corridor Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the street network (edges only), the waterway, and the corridor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = \"Bucharest\"\n",
    "river_name = \"Dâmbovița\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = gpd.read_file(f\"../../data/generated/network_edges_{city_name}.gpkg\")\n",
    "waterway = gpd.read_file(f\"../../data/generated/waterway_{river_name}.gpkg\")\n",
    "corridor = gpd.read_file(f\"../../data/generated/corridor_{river_name}.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the relevant geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterway_geometry = waterway.iloc[0].geometry\n",
    "corridor_geometry = corridor.iloc[0].geometry\n",
    "edge1_geometry = corridor.iloc[1].geometry\n",
    "edge2_geometry = corridor.iloc[2].geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuity analysis (modified `momepy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cross_check_links(unique, angle_pairs, angle_threshold):\n",
    "    \"\"\"\n",
    "    Modified version of the momepy function that identifies \"best\"\n",
    "    links between segments, dropping the reciprocity requirement.\n",
    "    \"\"\"\n",
    "    for edge in range(0, len(unique)):\n",
    "        best_p1 = unique[edge][4][0]\n",
    "        best_p2 = unique[edge][5][0]\n",
    "\n",
    "        if (\n",
    "            isinstance(best_p1, int)\n",
    "            # and edge in [unique[best_p1][4][0], unique[best_p1][5][0]]\n",
    "            and angle_pairs[\"%d_%d\" % (edge, best_p1)] > angle_threshold\n",
    "        ):\n",
    "            unique[edge][6] = best_p1\n",
    "        else:\n",
    "            unique[edge][6] = \"line_break\"\n",
    "\n",
    "        if (\n",
    "            isinstance(best_p2, int)\n",
    "            # and edge in [unique[best_p2][4][0], unique[best_p2][5][0]]\n",
    "            and angle_pairs[\"%d_%d\" % (edge, best_p2)] > angle_threshold\n",
    "        ):\n",
    "            unique[edge][7] = best_p2\n",
    "        else:\n",
    "            unique[edge][7] = \"line_break\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_lines_loop(n, unique_dict, bound_geometry):\n",
    "    \"\"\"\n",
    "    Modified version of the momepy function that merges the line\n",
    "    segments:\n",
    "    - crossing a provided boundary geometry is added as stopping condition;\n",
    "    - when assigning the best continuation segment on a vertex, we force the\n",
    "      following iteration to continue on the other vertex of the segment.\n",
    "      This is probably needed as a consequence of having dropped the reciprocity\n",
    "      requirement in assigning the best links.\n",
    "    \"\"\"\n",
    "    outlist = set()\n",
    "    current_edge1 = n\n",
    "    vertex = None\n",
    "\n",
    "    outlist.add(current_edge1)\n",
    "    while True:\n",
    "        p1, p2 = [tuple(i) for i in unique_dict[current_edge1][0]]\n",
    "        edge = shapely.LineString([p1, p2])\n",
    "        if not bound_geometry.contains(edge):\n",
    "            break\n",
    "        if (\n",
    "            isinstance(unique_dict[current_edge1][6], int)\n",
    "            and unique_dict[current_edge1][6] not in outlist\n",
    "            and ((vertex is None) or (vertex == p2))\n",
    "        ):\n",
    "            current_edge1 = unique_dict[current_edge1][6]\n",
    "            outlist.add(current_edge1)\n",
    "            vertex = tuple(p1)\n",
    "        elif (\n",
    "            isinstance(unique_dict[current_edge1][7], int)\n",
    "            and unique_dict[current_edge1][7] not in outlist\n",
    "            and ((vertex is None) or (vertex == p1))\n",
    "        ):\n",
    "            current_edge1 = unique_dict[current_edge1][7]\n",
    "            outlist.add(current_edge1)\n",
    "            vertex = tuple(p2)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    current_edge1 = n\n",
    "    vertex = None\n",
    "    while True:\n",
    "        p1, p2 = [tuple(i) for i in unique_dict[current_edge1][0]]\n",
    "        edge = shapely.LineString([p1, p2])\n",
    "        if not bound_geometry.contains(edge):\n",
    "            break\n",
    "        if (\n",
    "            isinstance(unique_dict[current_edge1][7], int)\n",
    "            and unique_dict[current_edge1][7] not in outlist\n",
    "            and ((vertex is None) or (vertex == p1))\n",
    "        ):\n",
    "            current_edge1 = unique_dict[current_edge1][7]\n",
    "            outlist.add(current_edge1)\n",
    "            vertex = tuple(p2)\n",
    "        elif (\n",
    "            isinstance(unique_dict[current_edge1][6], int)\n",
    "            and unique_dict[current_edge1][6] not in outlist\n",
    "            and ((vertex is None) or (vertex == p2))\n",
    "        ):\n",
    "            current_edge1 = unique_dict[current_edge1][6]\n",
    "            outlist.add(current_edge1)\n",
    "            vertex = tuple(p1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    outlist = list(outlist)\n",
    "    outlist.sort()\n",
    "    return outlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_simplified = momepy.roundabout_simplification(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show effect of roundabout simplification\n",
    "m = edges.explore(color=\"red\")\n",
    "m = edges_simplified.explore(m=m, color=\"black\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make continuity analysis using COINS\n",
    "ANGLE_THRESHOLD = 100.\n",
    "coins = momepy.coins.COINS(edges, angle_threshold=ANGLE_THRESHOLD, flow_mode=True)\n",
    "# get GDF of all line segments\n",
    "premerge = coins._create_gdf_premerge()\n",
    "# find the segments intersecting the waterway\n",
    "mask = premerge.intersects(waterway_geometry)\n",
    "crossings = premerge[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified assignment of best continuation edges (with threshold)\n",
    "_cross_check_links(coins.unique, coins.angle_pairs, ANGLE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the crossing points as intersections between the waterway and the street network\n",
    "crossing_points = crossings.intersection(waterway_geometry) # this should now be \"point\" geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grow strokes from the crossings\n",
    "geoms = []\n",
    "for idx in crossings.index:\n",
    "    indices = _merge_lines_loop(idx, coins.unique, corridor_geometry)\n",
    "    geoms.append(premerge.loc[indices].unary_union)\n",
    "strokes = gpd.GeoDataFrame(geometry=geoms, crs=crossings.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the strokes to \"cut\" the corridor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the crossing points to define clusters\n",
    "xy = np.column_stack([crossing_points.x, crossing_points.y])\n",
    "dbscan = sklearn.cluster.DBSCAN(eps=100, min_samples=1)\n",
    "dbscan.fit(xy)\n",
    "\n",
    "# assign cluster labels to the strokes\n",
    "strokes[\"cluster\"] = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the strokes that intersect both edges of the corridor\n",
    "mask = strokes.intersects(edge1_geometry) & strokes.intersects(edge2_geometry)\n",
    "filtered = strokes[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each cluster, select the shortest strokes\n",
    "filtered = filtered.assign(length=filtered.length)\n",
    "idx = filtered.groupby(\"cluster\").agg({\"length\": \"idxmin\"})\n",
    "shortest = filtered.loc[idx[\"length\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the strokes identified\n",
    "m = corridor.explore()\n",
    "m = shortest.explore(m=m, color=\"red\")\n",
    "m = crossings.explore(m=m, color=\"green\")\n",
    "# m.save(\"output.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_into_blocks(corridor: shapely.Polygon, edges: gpd.GeoSeries) -> gpd.GeoSeries:\n",
    "    \"\"\"\n",
    "    Cut a polygon into blocks, using the provided linestrings as edges.\n",
    "    \"\"\"\n",
    "    lines = edges.explode().to_list()\n",
    "    lines.append(corridor.boundary)\n",
    "    lines_merged = shapely.ops.linemerge(lines)\n",
    "    border_lines = shapely.ops.unary_union(lines_merged)\n",
    "    decomposition = shapely.ops.polygonize(border_lines)\n",
    "\n",
    "    # decomposition can extend beyond the corridor - clip it now\n",
    "    decomposition_gdf = gpd.GeoSeries(decomposition, crs=edges.crs)\n",
    "    clipped = decomposition_gdf.clip(corridor)\n",
    "\n",
    "    # drop elements at the edges (LineStrings and Points)\n",
    "    blocks = clipped[clipped.type == \"Polygon\"]\n",
    "    return blocks.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut corridor into blocks\n",
    "blocks = cut_into_blocks(corridor_geometry, shortest.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge blocks into river segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_blocks(blocks: gpd.GeoSeries, mask: pd.Series) -> Tuple[gpd.GeoSeries]:\n",
    "    \"\"\"\n",
    "    Merge a selection of blocks with the smallest adjacent ones.\n",
    "    Run this recursively, considering the blocks specified with a mask\n",
    "    from the smallest to the largest.\n",
    "    \"\"\"\n",
    "    # sort blocks (and mask) according to block areas\n",
    "    idx_sorted = blocks.area.sort_values().index\n",
    "    blocks = blocks[idx_sorted]\n",
    "    mask = mask[idx_sorted]\n",
    "\n",
    "    # get index of the first block to consider (i.e. the smallest)\n",
    "    idx = mask.idxmax()\n",
    "    if idx:\n",
    "        # extract block from table\n",
    "        block = blocks[idx]\n",
    "        blocks = blocks.drop(idx)\n",
    "        mask = mask.drop(idx)\n",
    "        # find adjacent blocks (i.e. blocks intersecting the target\n",
    "        # by a linestring)\n",
    "        intersection_type = blocks.intersection(block).geom_type\n",
    "        is_adjacent = intersection_type.str.contains(\"LineString\")\n",
    "        # get index of the first (i.e. smallest) adjacent block\n",
    "        idx_to_merge = is_adjacent.idxmax()\n",
    "        if not idx_to_merge:\n",
    "            raise ValueError(\n",
    "                f\"Block {idx_to_merge} does not have valid (LineString) \"\n",
    "                f\"instersections with other blocks.\"\n",
    "            )\n",
    "        # merge geometries\n",
    "        blocks.loc[idx_to_merge] = blocks[idx_to_merge].union(block)\n",
    "\n",
    "    if mask.any():\n",
    "        # recursively merge other blocks, if needed\n",
    "        blocks, mask = merge_blocks(blocks, mask)\n",
    "    return blocks, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge blocks that do not touch the waterway\n",
    "mask = ~blocks.intersects(waterway_geometry)\n",
    "blocks, _ = merge_blocks(blocks, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge blocks that do not extend across the corridor\n",
    "mask = ~(blocks.intersects(edge1_geometry) & blocks.intersects(edge2_geometry))\n",
    "segments, _ = merge_blocks(blocks, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize result and save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize resulting segments\n",
    "segments.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output\n",
    "segments.to_file(f\"../../data/generated/segments_{river_name}.gpkg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
